# -*- coding: utf-8 -*-
"""AirQualityPrediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KHpxKpZLgVsVq6gZwuZUGxqIVgu0I1nU

Project Overview

Goal:
Predict air pollution levels based on historical air quality data using time-series forecasting models (LSTMs).

Libraries Required:
pandas, numpy – Data handling
matplotlib, seaborn – Visualization
scikit-learn – Data preprocessing
tensorflow.keras or torch – LSTM model training

Step 1: Install and Import Dependencies

Run this in Google Colab
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout

from google.colab import drive
drive.mount('/content/drive')

""" Step 2: Load and Explore the Dataset

Download the dataset and load it into a Pandas DataFrame.
"""

import pandas as pd

file_path = "/content/drive/My Drive/AirQuality.csv"


df = pd.read_csv(file_path, sep=";", encoding="utf-8")

# Display first few rows and column names
print(df.head())
print(df.columns)

# Remove extra spaces and special characters
df.columns = df.columns.str.strip().str.replace(r'\W+', '_', regex=True)

# Print cleaned column names
print(df.columns)

"""Step 3: Data Preprocessing
1. Select Features
"""

df = df[['CO_GT_', 'T', 'RH']].copy()
df.rename(columns={'T': 'Temperature', 'RH': 'Humidity', 'CO_GT_': 'CO_Level'}, inplace=True)

"""

2. Handle Missing Values"""

print(df.isnull().sum())  # Check missing values

# Fill missing values using forward fill (or change as needed)
df.fillna(method='ffill', inplace=True)

"""3. Normalize Data"""

# Convert columns with potential comma separators to numeric
for col in ['CO_Level', 'Temperature', 'Humidity']:
    df[col] = pd.to_numeric(df[col].astype(str).str.replace(',', '.', regex=False), errors='coerce')

# Now apply scaling
df_scaled = scaler.transform(df)

import joblib
scaler = MinMaxScaler()
scaler.fit(df[['CO_Level', 'Temperature', 'Humidity']])  # Fit first!

df_scaled = scaler.transform(df[['CO_Level', 'Temperature', 'Humidity']])  # Then transform


# Save the scaler
joblib.dump(scaler, 'scaler.pkl')

"""Step 4: Create Train-Test Splits

Define time-series windows for LSTM input.
"""

def create_sequences(data, time_steps=10):
    X, y = [], []
    for i in range(len(data) - time_steps):
        X.append(data[i:i+time_steps])
        y.append(data[i+time_steps, 0])  # Predict CO Level
    return np.array(X), np.array(y)

time_steps = 10
X, y = create_sequences(df_scaled, time_steps)

split = int(0.8 * len(X))  # 80% training, 20% testing
X_train, X_test = X[:split], X[split:]
y_train, y_test = y[:split], y[split:]

"""Step 5: Build & Train LSTM Model

Define an LSTM-based neural network:
"""

model = Sequential([
    LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),
    Dropout(0.2),
    LSTM(50, return_sequences=False),
    Dropout(0.2),
    Dense(25),
    Dense(1)  # Predict PM2.5
])

model.compile(optimizer='adam', loss='mean_squared_error')
model.summary()

"""Train the model:"""

history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=16)

"""Step 7: Evaluate the Model

Plot loss curve:
"""

plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.legend()
plt.show()

"""Predict and compare with actual values:"""

y_pred = model.predict(X_test.reshape(-1, time_steps, 3))


plt.figure(figsize=(10,5))
plt.plot(y_test, label='Actual CO Level')
plt.plot(y_pred, label='Predicted CO Level')
plt.legend()
plt.show()

"""Step 7: Deploy trained model using
Streamlit for an interactive dashboard
"""

from google.colab import files

joblib.dump(scaler, 'scaler.pkl')
files.download('scaler.pkl')

# Save the model
model.save('air_quality_model.h5')
files.download('air_quality_model.h5')

model.summary()